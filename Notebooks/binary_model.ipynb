{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29c7d0d-b2a5-45de-b142-86d71179f60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded: (2830743, 79)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Load all CSV files\n",
    "path = r\"C:\\Users\\vacha\\Two-Stage-NIDS\\MachineLearningCSV\\MachineLearningCVE\\*.csv\"\n",
    "files = glob.glob(path)\n",
    "\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in files),\n",
    "               ignore_index=True)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Clean infinities\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "print(\"Dataset Loaded:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3741a638-0dc9-419a-a11e-d73063ff7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total packets\n",
    "df[\"Total Packets\"] = (\n",
    "    df[\"Total Fwd Packets\"] +\n",
    "    df[\"Total Backward Packets\"]\n",
    ")\n",
    "\n",
    "# Total bytes\n",
    "df[\"Total Bytes\"] = (\n",
    "    df[\"Total Length of Fwd Packets\"] +\n",
    "    df[\"Total Length of Bwd Packets\"]\n",
    ")\n",
    "\n",
    "# Packets/s and Bytes/s (already exist but ensure clean)\n",
    "df[\"Packets/s\"] = df[\"Flow Packets/s\"]\n",
    "df[\"Bytes/s\"] = df[\"Flow Bytes/s\"]\n",
    "\n",
    "# Mean packet length (combined)\n",
    "df[\"Mean Packet Length\"] = (\n",
    "    df[\"Total Bytes\"] /\n",
    "    df[\"Total Packets\"].replace(0, 1)\n",
    ")\n",
    "\n",
    "# Directional\n",
    "df[\"Fwd Packets\"] = df[\"Total Fwd Packets\"]\n",
    "df[\"Bwd Packets\"] = df[\"Total Backward Packets\"]\n",
    "df[\"Fwd Bytes\"] = df[\"Total Length of Fwd Packets\"]\n",
    "df[\"Bwd Bytes\"] = df[\"Total Length of Bwd Packets\"]\n",
    "\n",
    "# TCP Flags\n",
    "df[\"SYN Count\"] = df[\"SYN Flag Count\"]\n",
    "df[\"ACK Count\"] = df[\"ACK Flag Count\"]\n",
    "df[\"FIN Count\"] = df[\"FIN Flag Count\"]\n",
    "df[\"RST Count\"] = df[\"RST Flag Count\"]\n",
    "\n",
    "# Keep existing from dataset\n",
    "df[\"Flow Duration\"] = df[\"Flow Duration\"]\n",
    "df[\"Destination Port\"] = df[\"Destination Port\"]\n",
    "\n",
    "# For Std / Max / Min packet length,\n",
    "# use forward stats as approximation (since combined not available)\n",
    "df[\"Std Packet Length\"] = df[\"Fwd Packet Length Std\"]\n",
    "df[\"Max Packet Length\"] = df[\"Fwd Packet Length Max\"]\n",
    "df[\"Min Packet Length\"] = df[\"Fwd Packet Length Min\"]\n",
    "\n",
    "df[\"IAT Mean\"] = df[\"Flow IAT Mean\"]\n",
    "df[\"IAT Std\"] = df[\"Flow IAT Std\"]\n",
    "df[\"IAT Max\"] = df[\"Flow IAT Max\"]\n",
    "df[\"IAT Min\"] = df[\"Flow IAT Min\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "523ad7fa-f9e5-4f31-9591-d6891fd21416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Flow Duration  Total Packets  Total Bytes     Packets/s       Bytes/s  \\\n",
      "0              3              2           12  666666.66670  4.000000e+06   \n",
      "1            109              2           12   18348.62385  1.100917e+05   \n",
      "2             52              2           12   38461.53846  2.307692e+05   \n",
      "3             34              2           12   58823.52941  3.529412e+05   \n",
      "4              3              2           12  666666.66670  4.000000e+06   \n",
      "\n",
      "   Fwd Packets  Bwd Packets  Fwd Bytes  Bwd Bytes  Mean Packet Length  ...  \\\n",
      "0            2            0         12          0                 6.0  ...   \n",
      "1            1            1          6          6                 6.0  ...   \n",
      "2            1            1          6          6                 6.0  ...   \n",
      "3            1            1          6          6                 6.0  ...   \n",
      "4            2            0         12          0                 6.0  ...   \n",
      "\n",
      "   SYN Count  ACK Count  FIN Count  RST Count  IAT Mean  IAT Std  IAT Max  \\\n",
      "0          0          1          0          0       3.0      0.0        3   \n",
      "1          0          1          0          0     109.0      0.0      109   \n",
      "2          0          1          0          0      52.0      0.0       52   \n",
      "3          0          1          0          0      34.0      0.0       34   \n",
      "4          0          1          0          0       3.0      0.0        3   \n",
      "\n",
      "   IAT Min  Destination Port   Label  \n",
      "0        3             54865  BENIGN  \n",
      "1      109             55054  BENIGN  \n",
      "2       52             55055  BENIGN  \n",
      "3       34             46236  BENIGN  \n",
      "4        3             54863  BENIGN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "final_features = [\n",
    "    \"Flow Duration\",\n",
    "    \"Total Packets\",\n",
    "    \"Total Bytes\",\n",
    "    \"Packets/s\",\n",
    "    \"Bytes/s\",\n",
    "\n",
    "    \"Fwd Packets\",\n",
    "    \"Bwd Packets\",\n",
    "    \"Fwd Bytes\",\n",
    "    \"Bwd Bytes\",\n",
    "\n",
    "    \"Mean Packet Length\",\n",
    "    \"Std Packet Length\",\n",
    "    \"Max Packet Length\",\n",
    "    \"Min Packet Length\",\n",
    "\n",
    "    \"SYN Count\",\n",
    "    \"ACK Count\",\n",
    "    \"FIN Count\",\n",
    "    \"RST Count\",\n",
    "\n",
    "    \"IAT Mean\",\n",
    "    \"IAT Std\",\n",
    "    \"IAT Max\",\n",
    "    \"IAT Min\",\n",
    "\n",
    "    \"Destination Port\"\n",
    "]\n",
    "\n",
    "df_model = df[final_features + [\"Label\"]].copy()\n",
    "\n",
    "print(df_model.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc620336-c50c-4fc2-8051-82c302b4d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[\"BinaryLabel\"] = df_model[\"Label\"].apply(\n",
    "    lambda x: 0 if x == \"BENIGN\" else 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9a3cd4-1ea5-423d-a1b4-7e8eaa0a8ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryLabel\n",
      "0    557646\n",
      "1    557646\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "benign = df_model[df_model[\"BinaryLabel\"] == 0]\n",
    "attack = df_model[df_model[\"BinaryLabel\"] == 1]\n",
    "\n",
    "benign_down = resample(\n",
    "    benign,\n",
    "    replace=False,\n",
    "    n_samples=len(attack),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_balanced = pd.concat([benign_down, attack])\n",
    "\n",
    "print(df_balanced[\"BinaryLabel\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7225f33d-b202-4345-a579-9b1bfa56f8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9338 - loss: 0.1925 - val_accuracy: 0.9503 - val_loss: 0.1250\n",
      "Epoch 2/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9597 - loss: 0.1317 - val_accuracy: 0.9671 - val_loss: 0.1019\n",
      "Epoch 3/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.1111 - val_accuracy: 0.9716 - val_loss: 0.0826\n",
      "Epoch 4/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9718 - loss: 0.0924 - val_accuracy: 0.9730 - val_loss: 0.0805\n",
      "Epoch 5/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9774 - loss: 0.0755 - val_accuracy: 0.9766 - val_loss: 0.0737\n",
      "Epoch 6/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9814 - loss: 0.0637 - val_accuracy: 0.9721 - val_loss: 0.0725\n",
      "Epoch 7/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.0614 - val_accuracy: 0.9835 - val_loss: 0.0548\n",
      "Epoch 8/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0588 - val_accuracy: 0.9663 - val_loss: 0.0811\n",
      "Epoch 9/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9828 - loss: 0.0586 - val_accuracy: 0.9827 - val_loss: 0.0540\n",
      "Epoch 10/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0580 - val_accuracy: 0.9878 - val_loss: 0.0408\n",
      "Epoch 11/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9843 - loss: 0.0535 - val_accuracy: 0.9856 - val_loss: 0.0420\n",
      "Epoch 12/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9834 - loss: 0.0564 - val_accuracy: 0.9532 - val_loss: 0.0806\n",
      "Epoch 13/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.0517 - val_accuracy: 0.9892 - val_loss: 0.0346\n",
      "Epoch 14/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0489 - val_accuracy: 0.9904 - val_loss: 0.0289\n",
      "Epoch 15/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9844 - loss: 0.0521 - val_accuracy: 0.9841 - val_loss: 0.0504\n",
      "Epoch 16/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0522 - val_accuracy: 0.9868 - val_loss: 0.0348\n",
      "Epoch 17/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0477 - val_accuracy: 0.9898 - val_loss: 0.0313\n",
      "\u001b[1m6971/6971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0294\n",
      "Test Accuracy: 0.9904195666313171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import joblib\n",
    "\n",
    "X = df_balanced[final_features]\n",
    "y = df_balanced[\"BinaryLabel\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "class_weight = {0: 1, 1: 1.5}\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=1024,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14662c9e-6f2e-4a31-b79e-3b6d0b5a0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced[final_features].values\n",
    "y = df_balanced[\"BinaryLabel\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38b65822-da5c-46d2-86e5-9b837e9173fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6971/6971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9411814811327944\n",
      "\n",
      "===== Fold 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6971/6971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9373215158321341\n",
      "\n",
      "===== Fold 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6971/6971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9460633557191404\n",
      "\n",
      "===== Fold 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6971/6971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9384823678146491\n",
      "\n",
      "===== Fold 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6971/6971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9384958172313927\n",
      "\n",
      "===== Cross Validation Results =====\n",
      "Average Accuracy: 0.940308907546022\n",
      "Std Deviation: 0.0031439819202066163\n",
      "\n",
      "===== Confusion Matrix =====\n",
      "[[526788  30858]\n",
      " [ 35715 521931]]\n",
      "\n",
      "===== Classification Report =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94    557646\n",
      "           1       0.94      0.94      0.94    557646\n",
      "\n",
      "    accuracy                           0.94   1115292\n",
      "   macro avg       0.94      0.94      0.94   1115292\n",
      "weighted avg       0.94      0.94      0.94   1115292\n",
      "\n",
      "\n",
      "===== Missed Attack Types =====\n",
      "Original_Label\n",
      "DoS Hulk                      23070\n",
      "DoS GoldenEye                  7410\n",
      "SSH-Patator                    1636\n",
      "Web Attack � Brute Force       1374\n",
      "Bot                             777\n",
      "Web Attack � XSS                629\n",
      "DoS slowloris                   256\n",
      "DoS Slowhttptest                230\n",
      "DDoS                            154\n",
      "PortScan                        120\n",
      "Infiltration                     22\n",
      "Web Attack � Sql Injection       16\n",
      "Heartbleed                       11\n",
      "FTP-Patator                      10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "all_original_labels = []   # ← IMPORTANT\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Original multiclass labels for diagnosis\n",
    "    original_test_labels = df_balanced[\"Label\"].iloc[test_index].values\n",
    "\n",
    "\n",
    "    # Scale per fold\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=30,\n",
    "        batch_size=1024,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    probs = model.predict(X_test).ravel()\n",
    "\n",
    "    threshold = 0.30\n",
    "    y_pred = (probs > threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    fold_accuracies.append(acc)\n",
    "\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_pred.extend(y_pred)\n",
    "    all_original_labels.extend(original_test_labels)\n",
    "\n",
    "    print(\"Fold Accuracy:\", acc)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# FINAL CROSS-VALIDATION RESULTS\n",
    "# ==========================\n",
    "\n",
    "print(\"\\n===== Cross Validation Results =====\")\n",
    "print(\"Average Accuracy:\", np.mean(fold_accuracies))\n",
    "print(\"Std Deviation:\", np.std(fold_accuracies))\n",
    "\n",
    "print(\"\\n===== Confusion Matrix =====\")\n",
    "print(confusion_matrix(all_y_true, all_y_pred))\n",
    "\n",
    "print(\"\\n===== Classification Report =====\")\n",
    "print(classification_report(all_y_true, all_y_pred))\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# FALSE NEGATIVE DIAGNOSIS\n",
    "# ==========================\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"True_Binary\": all_y_true,\n",
    "    \"Pred_Binary\": all_y_pred,\n",
    "    \"Original_Label\": all_original_labels\n",
    "})\n",
    "\n",
    "false_negatives = results_df[\n",
    "    (results_df[\"True_Binary\"] == 1) &\n",
    "    (results_df[\"Pred_Binary\"] == 0)\n",
    "]\n",
    "\n",
    "print(\"\\n===== Missed Attack Types =====\")\n",
    "print(false_negatives[\"Original_Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85c2e744-d952-4246-a7e5-2ed93a655a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9332 - loss: 0.1945 - val_accuracy: 0.9561 - val_loss: 0.1188\n",
      "Epoch 2/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9575 - loss: 0.1356 - val_accuracy: 0.9613 - val_loss: 0.1042\n",
      "Epoch 3/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9659 - loss: 0.1114 - val_accuracy: 0.9746 - val_loss: 0.0784\n",
      "Epoch 4/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9719 - loss: 0.0911 - val_accuracy: 0.9831 - val_loss: 0.0683\n",
      "Epoch 5/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9771 - loss: 0.0772 - val_accuracy: 0.9765 - val_loss: 0.0596\n",
      "Epoch 6/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0661 - val_accuracy: 0.9732 - val_loss: 0.1016\n",
      "Epoch 7/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9813 - loss: 0.0641 - val_accuracy: 0.9741 - val_loss: 0.0627\n",
      "Epoch 8/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9825 - loss: 0.0601 - val_accuracy: 0.9868 - val_loss: 0.0548\n",
      "Epoch 9/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0651 - val_accuracy: 0.9874 - val_loss: 0.0522\n",
      "Epoch 10/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9833 - loss: 0.0587 - val_accuracy: 0.9884 - val_loss: 0.0381\n",
      "Epoch 11/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9846 - loss: 0.0537 - val_accuracy: 0.9873 - val_loss: 0.0380\n",
      "Epoch 12/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9862 - loss: 0.0492 - val_accuracy: 0.9901 - val_loss: 0.0325\n",
      "Epoch 13/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9847 - loss: 0.0538 - val_accuracy: 0.9830 - val_loss: 0.0432\n",
      "Epoch 14/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.0511 - val_accuracy: 0.9874 - val_loss: 0.0388\n",
      "Epoch 15/30\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9845 - loss: 0.0538 - val_accuracy: 0.9790 - val_loss: 0.0546\n",
      "\u001b[1m6971/6971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0329\n",
      "Test Accuracy: 0.9900878071784973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import joblib\n",
    "\n",
    "X = df_balanced[final_features]\n",
    "y = df_balanced[\"BinaryLabel\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "class_weight = {0: 1, 1: 1.5}\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=1024,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6e00d24-94dd-4cdc-8cca-0b92c41a64cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9405 - loss: 0.1753\n",
      "Epoch 2/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9648 - loss: 0.1150\n",
      "Epoch 3/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9722 - loss: 0.0900\n",
      "Epoch 4/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0736\n",
      "Epoch 5/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0651\n",
      "Epoch 6/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0625\n",
      "Epoch 7/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0610\n",
      "Epoch 8/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9842 - loss: 0.0546\n",
      "Epoch 9/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0629\n",
      "Epoch 10/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0547\n",
      "Epoch 11/30\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9839 - loss: 0.0551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Binary Model Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# 1. Prepare Data\n",
    "# =========================\n",
    "\n",
    "X = df_balanced[final_features].values\n",
    "y = df_balanced[\"BinaryLabel\"].values\n",
    "\n",
    "# Scale entire dataset\n",
    "scaler_final = StandardScaler()\n",
    "X_scaled = scaler_final.fit_transform(X)\n",
    "\n",
    "# =========================\n",
    "# 2. Build Final Model\n",
    "# =========================\n",
    "\n",
    "final_model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "final_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3. Training Setup\n",
    "# =========================\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "class_weight = {0: 1, 1: 1.5}  # Give slightly higher importance to ATTACK\n",
    "\n",
    "# =========================\n",
    "# 4. Train On FULL Dataset\n",
    "# =========================\n",
    "\n",
    "final_model.fit(\n",
    "    X_scaled,\n",
    "    y,\n",
    "    epochs=30,\n",
    "    batch_size=1024,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 5. Save Everything\n",
    "# =========================\n",
    "\n",
    "final_model.save(\"binary_model_final.h5\")\n",
    "joblib.dump(scaler_final, \"binary_scaler_final.pkl\")\n",
    "joblib.dump(final_features, \"binary_features_final.pkl\")\n",
    "\n",
    "print(\"✅ Final Binary Model Saved Successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83559aec-387c-4542-b3e0-de4d796fbd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nids)",
   "language": "python",
   "name": "nids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
