{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897e359a-dd6c-4562-a5e5-ed9b96edf537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Dataset Shape: (425878, 79)\n",
      "Label\n",
      "DoS Hulk                      172849\n",
      "DDoS                          128016\n",
      "PortScan                       90819\n",
      "DoS GoldenEye                  10286\n",
      "FTP-Patator                     5933\n",
      "DoS slowloris                   5385\n",
      "DoS Slowhttptest                5228\n",
      "SSH-Patator                     3219\n",
      "Bot                             1953\n",
      "Web Attack � Brute Force        1470\n",
      "Web Attack � XSS                 652\n",
      "Infiltration                      36\n",
      "Web Attack � Sql Injection        21\n",
      "Heartbleed                        11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "path = r\"C:\\Users\\vacha\\Two-Stage-NIDS\\MachineLearningCSV\\MachineLearningCVE\\*.csv\"\n",
    "files = glob.glob(path)\n",
    "\n",
    "df = pd.concat(\n",
    "    (pd.read_csv(f, low_memory=False) for f in files),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove BENIGN for multiclass\n",
    "df = df[df[\"Label\"] != \"BENIGN\"]\n",
    "\n",
    "print(\"Multiclass Dataset Shape:\", df.shape)\n",
    "print(df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c66255-c999-4893-8cf3-8f8c8c0781b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dos_labels = [\n",
    "    \"DoS Hulk\",\n",
    "    \"DoS GoldenEye\",\n",
    "    \"DoS slowloris\",\n",
    "    \"DoS Slowhttptest\"\n",
    "]\n",
    "\n",
    "df[\"Label\"] = df[\"Label\"].replace(dos_labels, \"DoS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6472d5-2a8b-424c-89c7-857a9b0caf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_labels = [\n",
    "    \"DoS\",\n",
    "    \"PortScan\",\n",
    "    \"FTP-Patator\",\n",
    "    \"SSH-Patator\"\n",
    "]\n",
    "\n",
    "df_multi = df[df[\"Label\"].isin(multiclass_labels)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8402ab6c-04d8-455e-b8ee-4405590160f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Done.\n"
     ]
    }
   ],
   "source": [
    "# ---------------- FEATURE ENGINEERING FOR MULTICLASS ----------------\n",
    "\n",
    "# Total packets\n",
    "df_multi[\"Total Packets\"] = (\n",
    "    df_multi[\"Total Fwd Packets\"] +\n",
    "    df_multi[\"Total Backward Packets\"]\n",
    ")\n",
    "\n",
    "# Total bytes\n",
    "df_multi[\"Total Bytes\"] = (\n",
    "    df_multi[\"Total Length of Fwd Packets\"] +\n",
    "    df_multi[\"Total Length of Bwd Packets\"]\n",
    ")\n",
    "\n",
    "df_multi[\"Packets/s\"] = df_multi[\"Flow Packets/s\"]\n",
    "df_multi[\"Bytes/s\"] = df_multi[\"Flow Bytes/s\"]\n",
    "\n",
    "df_multi[\"Mean Packet Length\"] = (\n",
    "    df_multi[\"Total Bytes\"] /\n",
    "    df_multi[\"Total Packets\"].replace(0, 1)\n",
    ")\n",
    "\n",
    "df_multi[\"Fwd Packets\"] = df_multi[\"Total Fwd Packets\"]\n",
    "df_multi[\"Bwd Packets\"] = df_multi[\"Total Backward Packets\"]\n",
    "df_multi[\"Fwd Bytes\"] = df_multi[\"Total Length of Fwd Packets\"]\n",
    "df_multi[\"Bwd Bytes\"] = df_multi[\"Total Length of Bwd Packets\"]\n",
    "\n",
    "df_multi[\"SYN Count\"] = df_multi[\"SYN Flag Count\"]\n",
    "df_multi[\"ACK Count\"] = df_multi[\"ACK Flag Count\"]\n",
    "df_multi[\"FIN Count\"] = df_multi[\"FIN Flag Count\"]\n",
    "df_multi[\"RST Count\"] = df_multi[\"RST Flag Count\"]\n",
    "\n",
    "df_multi[\"Std Packet Length\"] = df_multi[\"Fwd Packet Length Std\"]\n",
    "df_multi[\"Max Packet Length\"] = df_multi[\"Fwd Packet Length Max\"]\n",
    "df_multi[\"Min Packet Length\"] = df_multi[\"Fwd Packet Length Min\"]\n",
    "\n",
    "df_multi[\"IAT Mean\"] = df_multi[\"Flow IAT Mean\"]\n",
    "df_multi[\"IAT Std\"] = df_multi[\"Flow IAT Std\"]\n",
    "df_multi[\"IAT Max\"] = df_multi[\"Flow IAT Max\"]\n",
    "df_multi[\"IAT Min\"] = df_multi[\"Flow IAT Min\"]\n",
    "\n",
    "# Clean again\n",
    "df_multi.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df_multi.fillna(0, inplace=True)\n",
    "\n",
    "print(\"Feature Engineering Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe9cec4-6255-4420-b4ad-7216ceacfc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = [\n",
    "    \"Flow Duration\", \"Total Packets\", \"Total Bytes\",\n",
    "    \"Packets/s\", \"Bytes/s\",\n",
    "    \"Fwd Packets\", \"Bwd Packets\",\n",
    "    \"Fwd Bytes\", \"Bwd Bytes\",\n",
    "    \"Mean Packet Length\", \"Std Packet Length\",\n",
    "    \"Max Packet Length\", \"Min Packet Length\",\n",
    "    \"SYN Count\", \"ACK Count\", \"FIN Count\", \"RST Count\",\n",
    "    \"IAT Mean\", \"IAT Std\", \"IAT Max\", \"IAT Min\",\n",
    "    \"Destination Port\"\n",
    "]\n",
    "\n",
    "X = df_multi[final_features].values\n",
    "y = df_multi[\"Label\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6bb009-1401-43fd-8a3f-07462e1b65eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['DoS' 'FTP-Patator' 'PortScan' 'SSH-Patator']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(\"Classes:\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9711666-ccdb-429a-bf81-7aa3445aa8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9977870080348631\n",
      "\n",
      "===== Fold 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9975146397930001\n",
      "\n",
      "===== Fold 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9977529620046303\n",
      "\n",
      "===== Fold 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9982636524581234\n",
      "\n",
      "===== Fold 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Fold Accuracy: 0.9975997140084776\n",
      "\n",
      "===== Cross Validation Results =====\n",
      "Average Accuracy: 0.997783595259819\n",
      "Std Deviation: 0.00025982852604265484\n",
      "\n",
      "===== Confusion Matrix =====\n",
      "[[193540    117     90      1]\n",
      " [    17   5912      4      0]\n",
      " [   156      0  90663      0]\n",
      " [   233     14     19   2953]]\n",
      "\n",
      "===== Classification Report =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DoS       1.00      1.00      1.00    193748\n",
      " FTP-Patator       0.98      1.00      0.99      5933\n",
      "    PortScan       1.00      1.00      1.00     90819\n",
      " SSH-Patator       1.00      0.92      0.96      3219\n",
      "\n",
      "    accuracy                           1.00    293719\n",
      "   macro avg       0.99      0.98      0.99    293719\n",
      "weighted avg       1.00      1.00      1.00    293719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y_encoded)):\n",
    "\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
    "\n",
    "    # Scale per fold (NO DATA LEAKAGE)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(le.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=30,\n",
    "        batch_size=1024,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    fold_accuracies.append(acc)\n",
    "\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    print(\"Fold Accuracy:\", acc)\n",
    "\n",
    "print(\"\\n===== Cross Validation Results =====\")\n",
    "print(\"Average Accuracy:\", np.mean(fold_accuracies))\n",
    "print(\"Std Deviation:\", np.std(fold_accuracies))\n",
    "\n",
    "print(\"\\n===== Confusion Matrix =====\")\n",
    "print(confusion_matrix(all_y_true, all_y_pred))\n",
    "\n",
    "print(\"\\n===== Classification Report =====\")\n",
    "print(classification_report(all_y_true, all_y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23200253-fccc-4483-af66-3e86d8f597d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vacha\\anaconda3\\envs\\nids\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1121\n",
      "Epoch 2/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0186\n",
      "Epoch 3/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0123\n",
      "Epoch 4/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0112\n",
      "Epoch 5/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0091\n",
      "Epoch 6/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 0.0081\n",
      "Epoch 7/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0070\n",
      "Epoch 8/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0064\n",
      "Epoch 9/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0059\n",
      "Epoch 10/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0057\n",
      "Epoch 11/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0056\n",
      "Epoch 12/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0052\n",
      "Epoch 13/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0050\n",
      "Epoch 14/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0049\n",
      "Epoch 15/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0050\n",
      "Epoch 16/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0047\n",
      "Epoch 17/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0046\n",
      "Epoch 18/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0047\n",
      "Epoch 19/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0045\n",
      "Epoch 20/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0045\n",
      "Epoch 21/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0042\n",
      "Epoch 22/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0041\n",
      "Epoch 23/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0042\n",
      "Epoch 24/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0041\n",
      "Epoch 25/25\n",
      "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1670416e2c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Scale entire dataset\n",
    "scaler_final = StandardScaler()\n",
    "X_scaled = scaler_final.fit_transform(X)\n",
    "\n",
    "final_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "final_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_scaled,\n",
    "    y_encoded,\n",
    "    epochs=25,\n",
    "    batch_size=1024,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "332261d0-19c4-4be5-bde6-c752eff46a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "final_model.save(\"multiclass_model.h5\")\n",
    "joblib.dump(scaler_final, \"multiclass_scaler.pkl\")\n",
    "joblib.dump(final_features, \"multiclass_features.pkl\")\n",
    "joblib.dump(le, \"multiclass_label_encoder.pkl\")\n",
    "\n",
    "print(\"Multiclass model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224a7d4-a456-4765-902c-fe16af0e19e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nids)",
   "language": "python",
   "name": "nids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
